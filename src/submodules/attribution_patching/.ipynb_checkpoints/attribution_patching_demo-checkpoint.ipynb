{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a1ec8d-6634-4bc8-bda7-72f664563358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\a\\AppData\\Local\\Temp\\ipykernel_21324\\2870982339.py:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  sys.path.append('D:\\Code\\deception_and_jailbreak')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('D:\\Code\\deception_and_jailbreak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94b360a3c2fcbedd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T08:55:24.794219Z",
     "start_time": "2024-09-08T08:55:23.754260Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "from typing import List, Optional, Callable, Tuple, Dict, Literal, Set, Union\n",
    "import numpy as np\n",
    "from matplotlib.widgets import EllipseSelector\n",
    "from torch import Tensor\n",
    "from jaxtyping import Float, Int, Bool\n",
    "import einops\n",
    "import os\n",
    "import argparse\n",
    "from pipeline.configs.config_generation import Config\n",
    "from datasets import load_dataset\n",
    "import sae_lens\n",
    "import pysvelte\n",
    "from torchtyping import TensorType as TT\n",
    "from IPython import get_ipython\n",
    "from pathlib import Path\n",
    "\n",
    "# ipython = get_ipython()\n",
    "# Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "# ipython.magic(\"load_ext autoreload\")\n",
    "# ipython.magic(\"autoreload 2\")\n",
    "from IPython.display import HTML, Markdown\n",
    "from sae_lens import HookedSAETransformer\n",
    "from tqdm import tqdm\n",
    "from src.submodules.evaluations.run_evaluate_generation_deception import (\n",
    "    plot_lying_honest_performance,\n",
    ")\n",
    "from src.submodules.evaluations.run_evaluate_generation_deception import (\n",
    "    evaluate_generation_deception,\n",
    ")\n",
    "from functools import partial\n",
    "import torch\n",
    "from src.submodules.dataset.task_and_dataset_deception import (\n",
    "    load_and_sample_datasets,\n",
    "    construct_prompt,\n",
    ")\n",
    "from src.submodules.model.load_model import load_model\n",
    "from transformer_lens import utils, HookedTransformer, ActivationCache\n",
    "from rich.table import Table, Column\n",
    "from rich import print as rprint\n",
    "from src.utils.plotly_utils import imshow, line, scatter, bar\n",
    "import plotly.io as pio\n",
    "import circuitsvis as cv  # for visualize attetnion pattern\n",
    "\n",
    "from IPython.display import display, HTML  # for visualize attetnion pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d1c1a79-a1db-4086-92fa-d17bf8c9f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.notebook as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtyping import TensorType as TT\n",
    "from typing import List, Union, Optional, Callable\n",
    "from functools import partial\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML, Markdown\n",
    "\n",
    "import pysvelte # for attention visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10be6ab257530688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\a\\AppData\\Local\\Temp\\ipykernel_21324\\1059809029.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  save_dir = \"D:\\Data\\deception\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_path = \"gpt2-small\"\n",
    "save_dir = \"D:\\Data\\deception\"\n",
    "task_name = \"deception\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "224d07b45de4885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(model_path='gpt2-small',\n",
      "       model_alias='gpt2-small',\n",
      "       task_name='deception',\n",
      "       save_dir='D:\\\\Data\\\\deception',\n",
      "       contrastive_label=('honest', 'lying'),\n",
      "       dtype='default',\n",
      "       n_train=2,\n",
      "       n_test=50,\n",
      "       batch_size=2,\n",
      "       max_new_tokens=2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if task_name == \"deception\":\n",
    "    contrastive_label = (\"honest\", \"lying\")\n",
    "\n",
    "# 0. Set configuration\n",
    "model_alias = os.path.basename(model_path)\n",
    "cfg = Config(\n",
    "    model_path=model_path,\n",
    "    model_alias=model_alias,\n",
    "    task_name=task_name,\n",
    "    contrastive_label=contrastive_label,\n",
    "    save_dir=save_dir,\n",
    ")\n",
    "pprint.pp(cfg)\n",
    "artifact_dir = cfg.artifact_path()\n",
    "save_path = os.path.join(artifact_dir, \"attribution_patching\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce663e191db4423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      "device: cuda\n",
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "free(Gb): 9.874440192 total(Gb): 11.810701312\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Load model\n",
    "model = load_model(cfg)\n",
    "model.set_use_attn_result(True)\n",
    "model.cfg.use_attn_in = True\n",
    "model.cfg.use_hook_mlp_in = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c6012f-0e88-4cbc-bd83-5bde4c21878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def ioi_task_setup(\n",
    "    model,\n",
    ") -> tuple[List[str], List[tuple[str, str]]]:\n",
    "\n",
    "    prompts = [\n",
    "        \"When John and Mary went to the shops, John gave the bag to\",\n",
    "        \"When John and Mary went to the shops, Mary gave the bag to\",\n",
    "        \"When Tom and James went to the park, James gave the ball to\",\n",
    "        \"When Tom and James went to the park, Tom gave the ball to\",\n",
    "        \"When Dan and Sid went to the shops, Sid gave an apple to\",\n",
    "        \"When Dan and Sid went to the shops, Dan gave an apple to\",\n",
    "        \"After Martin and Amy went to the park, Amy gave a drink to\",\n",
    "        \"After Martin and Amy went to the park, Martin gave a drink to\",\n",
    "    ]\n",
    "    answers = [\n",
    "        (\" Mary\", \" John\"),\n",
    "        (\" John\", \" Mary\"),\n",
    "        (\" Tom\", \" James\"),\n",
    "        (\" James\", \" Tom\"),\n",
    "        (\" Dan\", \" Sid\"),\n",
    "        (\" Sid\", \" Dan\"),\n",
    "        (\" Martin\", \" Amy\"),\n",
    "        (\" Amy\", \" Martin\"),\n",
    "    ]\n",
    "\n",
    "    return prompts, answers\n",
    "\n",
    "# 2. ioi_task_setup\n",
    "print(\"loading data\")\n",
    "prompts, answers = ioi_task_setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_with_cache(model, clean_tokens, corrupted_tokens):\n",
    "\n",
    "    # Run the model and cache all activations\n",
    "    clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "    corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "\n",
    "    return clean_logits, corrupted_logits, clean_cache, corrupted_cache\n",
    "\n",
    "\n",
    "def get_logit_diff(\n",
    "    logits: Float[Tensor, \"batch seq d_vocab\"],\n",
    "    answer_token_indices: Float[Tensor, \"batch 2\"],\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Get logit difference between the correct and incorrect answers\n",
    "    :param logits:\n",
    "    :param answer_token_indices: answer token indices for correct and incorrect answers\n",
    "    :return: a scaler for mean logit difference across samples\n",
    "    \"\"\"\n",
    "    # (1) Get last token logits only\n",
    "    logits = logits[:, -1, :]  # [batch, d_vocab]\n",
    "\n",
    "    # (2) Get the index into correct dimension\n",
    "    # squeeze because the index tensor must have the same number of dimensions as input tensor\n",
    "    correct_index = answer_token_indices[:, 0].unsqueeze(1)  # [batch, 1]\n",
    "    incorrect_index = answer_token_indices[:, 1].unsqueeze(1)  # [batch, 1]\n",
    "\n",
    "    # (3) gather the logits corresponding to the indices\n",
    "    correct_logits = logits.gather(dim=1, index=correct_index)\n",
    "    incorrect_logits = logits.gather(dim=1, index=incorrect_index)\n",
    "\n",
    "    return (correct_logits - incorrect_logits).mean()\n",
    "\n",
    "\n",
    "def get_cache_fwd_and_bwd(model, metric, tokens):\n",
    "    filter_not_qkv_input = lambda name: \"_input\" not in name\n",
    "\n",
    "    def forward_cache_hook(act, hook):\n",
    "        cache[hook.name] = act.detach()\n",
    "\n",
    "    def backward_cache_hook(act, hook):\n",
    "        grad_cache[hook.name] = act.detach()\n",
    "\n",
    "    model.reset_hooks()\n",
    "    cache = {}\n",
    "    grad_cache = {}\n",
    "\n",
    "    model.add_hook(filter_not_qkv_input, forward_cache_hook, \"fwd\")\n",
    "    model.add_hook(filter_not_qkv_input, backward_cache_hook, \"bwd\")\n",
    "\n",
    "    value = metric(model(tokens))\n",
    "    value.backward()  # the loss for computing the backward pass\n",
    "    model.reset_hooks()\n",
    "    return (\n",
    "        value.item(),\n",
    "        ActivationCache(cache, model),\n",
    "        ActivationCache(grad_cache, model),\n",
    "    )\n",
    "\n",
    "\n",
    "def create_attention_attr(\n",
    "    model, clean_cache, clean_grad_cache\n",
    ") -> TT[\"batch\", \"layer\", \"head_index\", \"dest\", \"src\"]:\n",
    "    attention_stack = torch.stack(\n",
    "        [clean_cache[\"pattern\", l] for l in range(model.cfg.n_layers)], dim=0\n",
    "    )\n",
    "    attention_grad_stack = torch.stack(\n",
    "        [clean_grad_cache[\"pattern\", l] for l in range(model.cfg.n_layers)], dim=0\n",
    "    )\n",
    "    attention_attr = attention_grad_stack * attention_stack\n",
    "    attention_attr = einops.rearrange(\n",
    "        attention_attr,\n",
    "        \"layer batch head_index dest src -> batch layer head_index dest src\",\n",
    "    )\n",
    "\n",
    "    return attention_attr\n",
    "\n",
    "\n",
    "class AttributionPatching:\n",
    "    def __init__(self, model, prompts, answers):\n",
    "        self.model = model\n",
    "        self.prompts = prompts\n",
    "        self.answers = answers\n",
    "        self.clean_tokens, self.corrupted_tokens, self.answer_token_indices = (\n",
    "            self.get_tokens_and_indices()\n",
    "        )\n",
    "        self.clean_baseline = None\n",
    "        self.corrupted_baseline = None\n",
    "\n",
    "        self.head_names = [\n",
    "            f\"L{l}H{h}\"\n",
    "            for l in range(self.model.cfg.n_layers)\n",
    "            for h in range(self.model.cfg.n_heads)\n",
    "        ]\n",
    "        self.head_names_signed = [\n",
    "            f\"{name}{sign}\" for name in self.head_names for sign in [\"+\", \"-\"]\n",
    "        ]\n",
    "        self.head_nams_qkv = [\n",
    "            f\"{name}{act_name}\"\n",
    "            for name in self.head_names\n",
    "            for act_name in [\"Q\", \"K\", \"V\"]\n",
    "        ]\n",
    "        print(self.head_names[:5])\n",
    "        print(self.head_names_signed[:5])\n",
    "        print(self.head_nams_qkv[:5])\n",
    "\n",
    "    def get_tokens_and_indices(\n",
    "        self,\n",
    "    ) -> tuple[\n",
    "        [Tensor, \"batch seq d_vocab\"],\n",
    "        [Tensor, \"batch seq d_vocab\"],\n",
    "        [Tensor, \"batch 2\"],\n",
    "    ]:\n",
    "        clean_tokens = self.model.to_tokens(self.prompts)\n",
    "        # Swap each adjacent pair, with a hacky list comprehension\n",
    "        corrupted_tokens = clean_tokens[\n",
    "            [(i + 1 if i % 2 == 0 else i - 1) for i in range(len(clean_tokens))]\n",
    "        ]\n",
    "        print(\"Clean string 0\", self.model.to_string(clean_tokens[0]))\n",
    "        print(\"Corrupted string 0\", self.model.to_string(corrupted_tokens[0]))\n",
    "\n",
    "        answer_token_indices = torch.tensor(\n",
    "            [\n",
    "                [self.model.to_single_token(self.answers[i][j]) for j in range(2)]\n",
    "                for i in range(len(self.answers))\n",
    "            ],\n",
    "            device=self.model.cfg.device,\n",
    "        )\n",
    "        print(\"Answer token indices\", answer_token_indices)\n",
    "\n",
    "        return clean_tokens, corrupted_tokens, answer_token_indices\n",
    "\n",
    "    def get_baseline_logit_diff(self) -> None:\n",
    "        \"\"\"\n",
    "        get baseline logit differnece for lean and corrupted inputs\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        clean_logits, corrupted_logits, clean_cache, corrupted_cache = run_with_cache(\n",
    "            self.model, self.clean_tokens, self.corrupted_tokens\n",
    "        )\n",
    "        clean_logit_diff = get_logit_diff(\n",
    "            clean_logits, self.answer_token_indices\n",
    "        ).item()\n",
    "        print(f\"Clean logit diff: {clean_logit_diff:.4f}\")\n",
    "\n",
    "        corrupted_logit_diff = get_logit_diff(\n",
    "            corrupted_logits, self.answer_token_indices\n",
    "        ).item()\n",
    "        print(f\"Corrupted logit diff: {corrupted_logit_diff:.4f}\")\n",
    "\n",
    "        self.clean_baseline = clean_logit_diff\n",
    "        self.corrupted_baseline = corrupted_logit_diff\n",
    "\n",
    "        print(f\"Clean Baseline is 1: {self.ioi_metric(clean_logits).item():.4f}\")\n",
    "        print(\n",
    "            f\"Corrupted Baseline is 0: {self.ioi_metric(corrupted_logits).item():.4f}\"\n",
    "        )\n",
    "\n",
    "    def ioi_metric(\n",
    "        self,\n",
    "        logits: Float[Tensor, \"batch seq d_vocab\"],\n",
    "    ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Scale the logit difference between 0 and 1 (clean baseline will have logit diff =1, and corrupted baseline will have logit diff =0)\n",
    "        :param logits:\n",
    "        :param answer_token_indices:\n",
    "        :param clean_logit_diff:\n",
    "        :param corrupted_logit_diff:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        return (\n",
    "            get_logit_diff(logits, self.answer_token_indices) - self.corrupted_baseline\n",
    "        ) / (self.clean_baseline - self.corrupted_baseline)\n",
    "\n",
    "    def get_attention_attribution(self):\n",
    "        clean_value, clean_cache, clean_grad_cache = get_cache_fwd_and_bwd(\n",
    "            self.model, self.ioi_metric, self.clean_tokens\n",
    "        )\n",
    "        corrupted_value, corrupted_cache, corrupted_grad_cache = get_cache_fwd_and_bwd(\n",
    "            self.model, self.ioi_metric, self.corrupted_tokens\n",
    "        )\n",
    "        attention_attr = create_attention_attr(\n",
    "            self.model, clean_cache, clean_grad_cache\n",
    "        )\n",
    "        return attention_attr\n",
    "\n",
    "    def plot_attention_attr(\n",
    "        self, attention_attr, tokens, top_k=20, index=0, title=\"\", save_path=None\n",
    "    ):\n",
    "        if len(tokens.shape) == 2:\n",
    "            tokens = tokens[index]\n",
    "        if len(attention_attr.shape) == 5:\n",
    "            attention_attr = attention_attr[index]\n",
    "        attention_attr_pos = attention_attr.clamp(min=-1e-5)\n",
    "        attention_attr_neg = -attention_attr.clamp(max=1e-5)\n",
    "        attention_attr_signed = torch.stack(\n",
    "            [attention_attr_pos, attention_attr_neg], dim=0\n",
    "        )\n",
    "        attention_attr_signed = einops.rearrange(\n",
    "            attention_attr_signed,\n",
    "            \"sign layer head_index dest src -> (layer head_index sign) dest src\",\n",
    "        )\n",
    "        attention_attr_signed = attention_attr_signed / attention_attr_signed.max()\n",
    "        attention_attr_indices = (\n",
    "            attention_attr_signed.max(-1).values.max(-1).values.argsort(descending=True)\n",
    "        )\n",
    "        # print(attention_attr_indices.shape)\n",
    "        # print(attention_attr_indices)\n",
    "        attention_attr_signed = attention_attr_signed[attention_attr_indices, :, :]\n",
    "        head_labels = [self.head_names_signed[i.item()] for i in attention_attr_indices]\n",
    "\n",
    "        if title:\n",
    "            display(Markdown(\"### \" + title))\n",
    "\n",
    "        display(\n",
    "            pysvelte.AttentionMulti(\n",
    "                tokens=model.to_str_tokens(tokens),\n",
    "                attention=attention_attr_signed.permute(1, 2, 0)[:, :, :top_k],\n",
    "                head_labels=head_labels[:top_k],\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "        # save the visualization as .html file\n",
    "        # vis_path = save_path + os.sep + \"attention_attribution\" + os.sep + f\"top20.html\"\n",
    "        # if not os.path.exists(vis_path):\n",
    "        #     os.makedirs(vis_path)\n",
    "        # with open(vis_path, \"w\") as f:\n",
    "        #     f.write(vis)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb447bd50f0c3af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean string 0 <|endoftext|>When John and Mary went to the shops, John gave the bag to\n",
      "Corrupted string 0 <|endoftext|>When John and Mary went to the shops, Mary gave the bag to\n",
      "Answer token indices tensor([[ 5335,  1757],\n",
      "        [ 1757,  5335],\n",
      "        [ 4186,  3700],\n",
      "        [ 3700,  4186],\n",
      "        [ 6035, 15686],\n",
      "        [15686,  6035],\n",
      "        [ 5780, 14235],\n",
      "        [14235,  5780]], device='cuda:0')\n",
      "['L0H0', 'L0H1', 'L0H2', 'L0H3', 'L0H4']\n",
      "['L0H0+', 'L0H0-', 'L0H1+', 'L0H1-', 'L0H2+']\n",
      "['L0H0Q', 'L0H0K', 'L0H0V', 'L0H1Q', 'L0H1K']\n",
      "Clean logit diff: 3.5519\n",
      "Corrupted logit diff: -3.5519\n",
      "Clean Baseline is 1: 1.0000\n",
      "Corrupted Baseline is 0: 0.0000\n",
      "pysvelte components appear to be unbuilt or stale\n",
      "Running npm install...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\llmtt\\Lib\\site-packages\\IPython\\core\\formatters.py:347\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    345\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\code\\pysvelte\\pysvelte\\html.py:73\u001b[0m, in \u001b[0;36mHtml._repr_html_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_html_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhtml_inline_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\code\\pysvelte\\pysvelte\\html.py:113\u001b[0m, in \u001b[0;36mHtml.html_inline_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhtml_inline_str\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m    Render the HTML in \"colab inline\" format, with javascript from script paths\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m    (but ignoring \"dev mode\" and just requesting static pages, because it doesn't work in colab).\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mget_script_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscript_paths\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhtml_str()\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32md:\\code\\pysvelte\\pysvelte\\javascript.py:119\u001b[0m, in \u001b[0;36mget_script_tags\u001b[1;34m(paths, dev_host)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get html <script> tags to load the visualizations at paths.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    load it from a url based on dev_host.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dev_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# Although the get_script_tag() below would also trigger builds,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# doing it like this builds all needed assets in one pass which is\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# significantly faster.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[43mwebpack_if_necessary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m tags \u001b[38;5;241m=\u001b[39m [get_script_tag(path, dev_host\u001b[38;5;241m=\u001b[39mdev_host) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tags)\n",
      "File \u001b[1;32md:\\code\\pysvelte\\pysvelte\\javascript.py:59\u001b[0m, in \u001b[0;36mwebpack_if_necessary\u001b[1;34m(paths)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stale:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpysvelte components appear to be unbuilt or stale\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m     \u001b[43minstall_if_necessary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilding pysvelte components with webpack...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m paths:\n",
      "File \u001b[1;32md:\\code\\pysvelte\\pysvelte\\javascript.py:39\u001b[0m, in \u001b[0;36minstall_if_necessary\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_npm_install_necessary():\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning npm install...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnpm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--prefix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPYSVELTE_ROOT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llmtt\\Lib\\subprocess.py:408\u001b[0m, in \u001b[0;36mcheck_call\u001b[1;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_call\u001b[39m(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run command with arguments.  Wait for command to complete.  If\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    the exit code was zero then return, otherwise raise\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    CalledProcessError.  The CalledProcessError object will have the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;124;03m    check_call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 408\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retcode:\n\u001b[0;32m    410\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llmtt\\Lib\\subprocess.py:389\u001b[0m, in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;241m*\u001b[39mpopenargs, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    382\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run command with arguments.  Wait for command to complete or\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;124;03m    timeout, then return the returncode attribute.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m    retcode = call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m p\u001b[38;5;241m.\u001b[39mwait(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llmtt\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llmtt\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1540\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pysvelte.html.Html at 0x25621044800>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# initiate\n",
    "attribution_patching = AttributionPatching(model, prompts, answers)\n",
    "# get baseline logit diff\n",
    "attribution_patching.get_baseline_logit_diff()\n",
    "# get attention attribution\n",
    "attention_attr = attribution_patching.get_attention_attribution()\n",
    "# visualize attention pattern\n",
    "attribution_patching.plot_attention_attr(\n",
    "    attention_attr,\n",
    "    attribution_patching.clean_tokens,\n",
    "    top_k=20,\n",
    "    index=0,\n",
    "    title=\"\",\n",
    "    save_path=save_path,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb30f1d3-d319-40fd-b703-9f96eef42159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
